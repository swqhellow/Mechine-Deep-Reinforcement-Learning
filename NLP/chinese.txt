主导序列转导模型基于复杂的递归或卷积神经网络，包括编码器和解码器。性能最好的模型还通过注意力机制连接编码器和解码器。我们提出了一种新的简单网络架构，Transform，它完全基于注意力机制，完全省略了递归和卷积。在两个机器翻译任务上的实验表明，这些模型在质量上更优越，同时更具并行性，并且需要的训练时间明显更少。我们的模型在WMT 2014英语到德语翻译任务上实现了28.4 BLEU，比现有的最佳结果（包括集成）提高了2个BLEU以上。在WMT 2014英语到法语翻译任务上，我们的模型在八个GPU上训练3.5天后建立了一个新的单模型最先进的BLEU分数41.8，这是文献中最佳模型训练成本的一小部分。我们通过成功地将其应用于具有大量和有限训练数据的英语选区解析，证明了转换器可以很好地推广到其他任务。